{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading libraries"
      ],
      "metadata": {
        "id": "A-Bu5LEjbhoR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JMwy6TWsDnI1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "aCnP3FCjblxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"READYCPTfourthrun.csv\")"
      ],
      "metadata": {
        "id": "8bsHXNX-D9js"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separating matrix of features from the dependent variable"
      ],
      "metadata": {
        "id": "H9lMXb9vbwsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "PTzymbgCbvNj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting data into training and test sets"
      ],
      "metadata": {
        "id": "sRS1CGn0cG29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "s1Kvhh1jcKnh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Logistic Regression instance"
      ],
      "metadata": {
        "id": "zi4XjcvTcLzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()"
      ],
      "metadata": {
        "id": "kHIOHq_iECfN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Grid Search to find the best hyperparameters (tuning)\n"
      ],
      "metadata": {
        "id": "yJ-ytaj1cYyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    \"solver\": [\"liblinear\", \"newton-cg\", \"saga\", \"sag\", \"lbfgs\"],\n",
        "    \"max_iter\": [100, 500, 1000, 2000, 10000]\n",
        "}"
      ],
      "metadata": {
        "id": "2K63AWL1FfX7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the best parameters and estimator from the Grid Search\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B9T89HdJces_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "LhnuskUWFheN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of custom function to select accuracy-weighed features"
      ],
      "metadata": {
        "id": "NE1JUbY4clu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = list(range(x_train.shape[1]))\n",
        "initial_accuracy = accuracy_score(y_test, best_model.predict(x_test))\n",
        "\n",
        "for i in selected_features:\n",
        "    features_to_use = [feature for feature in selected_features if feature != i]\n",
        "\n",
        "    if len(features_to_use) > 0:\n",
        "        x_subset = x_train[:, features_to_use]\n",
        "        classifier.fit(x_subset, y_train)\n",
        "        y_pred_subset = classifier.predict(x_test[:, features_to_use])\n",
        "        accuracy_subset = accuracy_score(y_test, y_pred_subset)\n",
        "\n",
        "        if accuracy_subset > initial_accuracy:\n",
        "            print(f\"Removing feature in position {i} - Accuracy improved to {accuracy_subset:.4f}\")\n",
        "            initial_accuracy = accuracy_subset\n",
        "            selected_features = features_to_use\n",
        "        else:\n",
        "            print(f\"Keeping feature in position {i} - Accuracy: {accuracy_subset:.4f}\")\n",
        "    else:\n",
        "        print(f\"All features removed - Terminating Process\")\n",
        "        break\n",
        "\n",
        "print(\"Selected Features:\")\n",
        "for feature_index in selected_features:\n",
        "    if feature_index < len(dataset.columns) - 1:\n",
        "        print(dataset.columns[feature_index])\n",
        "    else:\n",
        "        print(\"Invalid Index\")"
      ],
      "metadata": {
        "id": "uja-DIE9FmAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit the best regressor on the training data\n",
        "\n"
      ],
      "metadata": {
        "id": "P8aUbRjzc0Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(x_train[:, selected_features], y_train)"
      ],
      "metadata": {
        "id": "zurnj0JvFtYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions on the test set using selected features\n",
        "\n"
      ],
      "metadata": {
        "id": "a3TQlpKhc3wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(x_test[:, selected_features])"
      ],
      "metadata": {
        "id": "1Eu-nPQ_FwhY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate performance on test set"
      ],
      "metadata": {
        "id": "17C08phUdKVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "KQO5LFmYFzcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Random Forest classifier instance"
      ],
      "metadata": {
        "id": "6MYVWrD_dVy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "vERmib6DdfPo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Grid Search to find the best hyperparameters (tuning)\n"
      ],
      "metadata": {
        "id": "i_k5MPBudiA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "CplDHv7DdoTc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the best parameters and estimator from the Grid Search\n"
      ],
      "metadata": {
        "id": "5SPGAN1vdxB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "n6Mq6Fqcdv6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of custom function to select accuracy-weighed features"
      ],
      "metadata": {
        "id": "8NCZKELKeEtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = list(range(x_train.shape[1]))\n",
        "initial_accuracy = accuracy_score(y_test, best_rf_model.predict(x_test))\n",
        "\n",
        "for i in selected_features:\n",
        "    features_to_use = [feature for feature in selected_features if feature != i]\n",
        "\n",
        "    if len(features_to_use) > 0:\n",
        "        x_subset = x_train[:, features_to_use]\n",
        "        rf_classifier.fit(x_subset, y_train)\n",
        "        y_pred_subset = rf_classifier.predict(x_test[:, features_to_use])\n",
        "        accuracy_subset = accuracy_score(y_test, y_pred_subset)\n",
        "\n",
        "        if accuracy_subset > initial_accuracy:\n",
        "            print(f\"Removing feature in position {i} - Accuracy improved to {accuracy_subset:.4f}\")\n",
        "            initial_accuracy = accuracy_subset\n",
        "            selected_features = features_to_use\n",
        "        else:\n",
        "            print(f\"Keeping feature in position {i} - Accuracy: {accuracy_subset:.4f}\")\n",
        "    else:\n",
        "        print(f\"All features removed - Terminating Process\")\n",
        "        break\n",
        "\n",
        "print(\"Selected Features:\")\n",
        "for feature_index in selected_features:\n",
        "    # Assuming 'dataset' has column names\n",
        "    if feature_index < len(dataset.columns) - 1:\n",
        "        print(dataset.columns[feature_index])\n",
        "    else:\n",
        "        print(\"Invalid Index\")"
      ],
      "metadata": {
        "id": "k_gEMGoNeENy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit the best regressor on the training data"
      ],
      "metadata": {
        "id": "u-dGHWdweOia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf_model.fit(x_train[:, selected_features], y_train)"
      ],
      "metadata": {
        "id": "ZW_bTDzZeOG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions on the test set using selected features"
      ],
      "metadata": {
        "id": "dZUtMi4feWOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_rf_model.predict(x_test[:, selected_features])"
      ],
      "metadata": {
        "id": "4zFbzc3feRVS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate performance on test set"
      ],
      "metadata": {
        "id": "s_KFdhlGebRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "858-0gbteaqa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}